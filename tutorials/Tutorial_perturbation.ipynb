{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning to predict the driver gene on example dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "Before running this script, please make sure:\n",
    "1. Download all files in the dataset and checkpoint links mentioned in CellNavi/README.md.\n",
    "2. Completed the preparation steps 0-3 in CellNavi/tutorials/README.md.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "url = \"https://ucc0e5b8ed82a72fc5a2f99aa081.dl.dropboxusercontent.com/cd/0/get/ClGGk1CQmoTYoHlYHd43QnZ399puxUPAdDosmZD5FFvg90_LzsayqVn76-XCfJLam2eVEv2s6oW8UGlIjlNSgtRzWzHSyigYeCgKyiNKSdlRgl3BUSiKz27ceaFUIOYwSliaKcEPQlLCpyYN5B82AM7zN5MxP_WEB_Ce0OO4hiX10g/file?_download_id=49996818229892190311348360354759554017146239774901417905492274051615&_log_download_success=1#\"\n",
    "\n",
    "\n",
    "save_path = \"../data/\"  # 替换为实际文件名和扩展名\n",
    "\n",
    "\n",
    "response = requests.get(url, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(save_path, \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "    print(f\"Successfully downloaded to {save_path}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the README.md for training preparations, including datasets and pretrained files. The links for examples can be found inCellNavi/README.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"global_batch_size\": 128,\n",
    "    \"local_batch_size\": 1,\n",
    "    \"n_cls\": 2058,\n",
    "    \"mixed_precision\": true,\n",
    "    \"nr_step\": 3000,\n",
    "    \"warmup_step\": 500,\n",
    "    \"lr\": 0.001,\n",
    "    \"chk_time_interval\": 3600,\n",
    "    \"chk_step_interval\": 100,\n",
    "\n",
    "    \"saved_dir\": \"../data/\",\n",
    "    \"pretrained_dir\": \"../data/\",\n",
    "    \"dataset_dir\": \"../data/\",\n",
    "    \"log_dir\": \"../data/log\",\n",
    "    \"model_dir\": \"../data/finetune/model\",\n",
    "    \"pretrain_model_dir\": \"../data/pretrain\",\n",
    "\n",
    "    \"train_data\": \"set3_example_train.h5ad\",\n",
    "    \"test_data\": \"set3_example_test.h5ad\",\n",
    "    \"dist_graph\" : \"shortest_path_integrated_network_setting3_all_genes.csv\",\n",
    "    \"adj_graph\" : \"integrated_network_setting3_all_genes.csv\"\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "with open('../config.json', 'w') as f:\n",
    "    json.dump(params, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 5690 × 19240\n",
       "    obs: 'nCount_RNA', 'nFeature_RNA', 'orig.ident', 'condition', 'guide_id', 'gene', 'gene_category', 'crispr', 'donor', 'percent.mt', 'percent.ribo', 'nCount_SCT', 'nFeature_SCT', 'S.Score', 'G2M.Score', 'Phase', 'old.ident', 'CD4.CD8.Score', 'CD4.or.CD8', 'SCT_snn_res.0.4', 'seurat_clusters', 'cluster_name', 'activation.score', 'perturbation'\n",
       "    var: 'gene_ids', 'n_cells'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Here we use the toy dataset 'set3_example_train.h5ad' and 'set3_example_test.h5ad' as an example. \n",
    "import scanpy as sc\n",
    "\n",
    "## The file_path should be the path where the training data is stored.\n",
    "train_file_path = '../data/set3_example_train.h5ad'\n",
    "adata_train = sc.read_h5ad(train_file_path)\n",
    "\n",
    "## The cell by gene matrix should be raw counts.\n",
    "adata_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CGGAATTAGACTTCAC-6         IFNG\n",
       "ATTACCTAGGAGATAG-5       INPPL1\n",
       "TGGGTTAGTTGTATGC-5         GRAP\n",
       "CTCCCTCTCGGTAGGA-8       P2RY14\n",
       "GACCTTCTCATCTATC-6        IKZF3\n",
       "                        ...    \n",
       "TTCAGGACAGCAATTC-6      ARHGDIB\n",
       "AGACAAACAAGAGCTG-5        IL2RB\n",
       "AACCAACCAGACTGCC-7     APOBEC3C\n",
       "CATGCAAGTACATACC-5         CD28\n",
       "ACGGTTAGTACGATCT-8    NO-TARGET\n",
       "Name: perturbation, Length: 5690, dtype: category\n",
       "Categories (70, object): ['ABCB10', 'AKAP12', 'ALX4', 'APOBEC3C', ..., 'TRAF3IP2', 'TRIM21', 'VAV1', 'WT1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The perturbation label is stored in adata.obs.perturbation\n",
    "adata_train.obs.perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### please adjust the parameters in common/config.py. The current parameters shown are the default paramters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The dataset link has been given in CellNavi/README.md.\n",
    "\n",
    "!chmod u+x launch_train.sh\n",
    "!./launch_train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results and evaluate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/isilon/tan_lab/pany3/CellNavi/tutorials/load_results.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset info: /home/pany3/pany3/CellNavi/dataset_full/set3_example_test.h5ad 3158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3158/3158 [16:09<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "## Here we load results on step 1000 as an example. \n",
    "## The link for 'checkpoint-step-1000.pth' has been given in CellNavi/README.md.\n",
    "\n",
    "%run load_results.py -c 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ABCB10    AKAP12      ALX4  APOBEC3C  APOBEC3D  \\\n",
      "TGCATCCTCGATCCAA-4 -7.821463 -1.156066  0.904565 -5.127326 -7.951521   \n",
      "TTGGATGGTATCCTCC-2 -7.477587 -1.947112 -1.975892 -1.696544 -7.003691   \n",
      "AACCACAGTCTCCCTA-1 -9.641579 -3.978698 -5.091012 -5.724802 -5.395859   \n",
      "TAGAGTCTCATGGATC-4 -1.639565 -2.339934  0.846601 -3.660203 -7.996193   \n",
      "TTTCAGTTCCATTCGC-2 -3.726980 -3.369183 -4.184911  0.105774 -1.985862   \n",
      "\n",
      "                       APOL2   ARHGDIB    BICDL2      CBY1       CD2  ...  \\\n",
      "TGCATCCTCGATCCAA-4 -1.957271  2.360333 -5.758391 -6.885813 -9.281010  ...   \n",
      "TTGGATGGTATCCTCC-2 -2.546962  1.258157 -2.950146 -0.769823 -4.229147  ...   \n",
      "AACCACAGTCTCCCTA-1 -5.997128 -5.460759 -0.255089 -5.033724 -3.466392  ...   \n",
      "TAGAGTCTCATGGATC-4 -2.124491  1.050665 -0.941778  1.620585 -2.813236  ...   \n",
      "TTTCAGTTCCATTCGC-2 -2.452409  2.454847 -1.646882 -0.831029 -1.429325  ...   \n",
      "\n",
      "                       TAGAP     TBX21  TNFRSF1A   TNFRSF1B   TNFRSF9  \\\n",
      "TGCATCCTCGATCCAA-4 -9.457092 -5.753242 -6.170871 -10.717887 -5.622791   \n",
      "TTGGATGGTATCCTCC-2 -2.295697 -5.560549 -3.188946 -10.100318 -3.876570   \n",
      "AACCACAGTCTCCCTA-1 -2.127382 -5.730026 -2.677795  -4.256061 -3.211844   \n",
      "TAGAGTCTCATGGATC-4 -0.399501 -3.543861 -5.370579 -10.807867 -0.852403   \n",
      "TTTCAGTTCCATTCGC-2 -0.681239 -5.872741 -4.059673  -7.269981 -2.935251   \n",
      "\n",
      "                    TNFRSF12A  TRAF3IP2    TRIM21      VAV1       WT1  \n",
      "TGCATCCTCGATCCAA-4  -1.512885 -8.452597 -1.819332 -5.750784 -2.827259  \n",
      "TTGGATGGTATCCTCC-2   0.070525 -3.797031 -4.854851 -7.181687  0.396741  \n",
      "AACCACAGTCTCCCTA-1   1.078254 -3.936965 -5.897006 -8.137145 -3.409272  \n",
      "TAGAGTCTCATGGATC-4   0.740322 -3.069075  0.221845 -9.051618 -1.450138  \n",
      "TTTCAGTTCCATTCGC-2   0.625919 -4.718899 -2.151842 -6.627671  0.087041  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('set3_test_example_results.csv', index_col=0)\n",
    "\n",
    "## The rows represent cell names and columns represent perturbed genes, with each value indicating the logits.\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy (for toy dataset): 0.510\n",
      "Testing F1 score (for toy dataset): 0.498\n"
     ]
    }
   ],
   "source": [
    "## The file_path should be the path where the testing data is stored.\n",
    "test_file_path = '../dataset_full/set3_example_test.h5ad'\n",
    "adata_test = sc.read_h5ad(test_file_path)\n",
    "perturb_gene = adata_test.obs['perturbation'].values\n",
    "\n",
    "df['pred_gene'] = df.idxmax(axis=1)\n",
    "pred_gene = df['pred_gene'].values\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(perturb_gene, pred_gene)\n",
    "f1 = f1_score(perturb_gene, pred_gene, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Testing accuracy (for toy dataset): {accuracy:.3f}\")\n",
    "print(f\"Testing F1 score (for toy dataset): {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scleap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
