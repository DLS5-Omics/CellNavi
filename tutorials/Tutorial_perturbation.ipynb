{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning to predict the driver gene on example dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "Before running this script, please make sure:\n",
    "1. Download all files in the dataset and checkpoint links mentioned in CellNavi/README.md.\n",
    "2. Completed the preparation steps 0-3 in CellNavi/tutorials/README.md.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the README.md for training preparations, including datasets and pretrained files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-12 19:03:37,177] torch.distributed.run: [WARNING] \n",
      "[2024-11-12 19:03:37,177] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-11-12 19:03:37,177] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2024-11-12 19:03:37,177] torch.distributed.run: [WARNING] *****************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset info: /data/tianzew/cellnavi/data_path/set3_example_train.h5ad 5690\n",
      "dataset info: /data/tianzew/cellnavi/data_path/set3_example_train.h5ad 5690\n",
      "dataset info: /data/tianzew/cellnavi/data_path/set3_example_train.h5ad 5690\n",
      "dataset info: /data/tianzew/cellnavi/data_path/set3_example_train.h5ad 5690\n",
      "dataset info: /data/tianzew/cellnavi/data_path/set3_example_test.h5ad 3158\n",
      "dataset info: /data/tianzew/cellnavi/data_path/set3_example_test.h5ad 3158\n",
      "dataset info: /data/tianzew/cellnavi/data_path/set3_example_test.h5ad 3158\n",
      "dataset info: /data/tianzew/cellnavi/data_path/set3_example_test.h5ad 3158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/tutorials/start_train.py\", line 34, in <module>\n",
      "    main()\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/tutorials/start_train.py\", line 28, in main\n",
      "    trainer.train()\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/trainer/trainer.py\", line 87, in train\n",
      "    step_forward()\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/trainer/trainer.py\", line 70, in step_forward\n",
      "    output = self.model(data)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1519, in forward\n",
      "    else self._run_ddp_forward(*inputs, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1355, in _run_ddp_forward\n",
      "    return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/model/finetune_model.py\", line 54, in forward\n",
      "    mask_attn_embed = self.graph_attn_bias(mask_attn).view(mask_attn.shape[0], 16, mask_attn.shape[1], mask_attn.shape[2])\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/sparse.py\", line 162, in forward\n",
      "    return F.embedding(\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/functional.py\", line 2233, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 492.00 MiB. GPU 0 has a total capacty of 15.72 GiB of which 101.56 MiB is free. Process 2612071 has 560.00 MiB memory in use. Process 3612818 has 14.31 GiB memory in use. Including non-PyTorch memory, this process has 780.00 MiB memory in use. Of the allocated memory 354.90 MiB is allocated by PyTorch, and 55.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/tutorials/start_train.py\", line 34, in <module>\n",
      "    main()\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/tutorials/start_train.py\", line 28, in main\n",
      "    trainer.train()\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/trainer/trainer.py\", line 87, in train\n",
      "    step_forward()\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/trainer/trainer.py\", line 70, in step_forward\n",
      "    output = self.model(data)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1519, in forward\n",
      "    else self._run_ddp_forward(*inputs, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1355, in _run_ddp_forward\n",
      "    return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/model/finetune_model.py\", line 56, in forward\n",
      "    x = self.pretrain(data, in_degree_embed, out_degree_embed, mask_attn_embed)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/model/pretrain_model.py\", line 84, in forward\n",
      "    src, emb = self.encoder(src, mask, mask_attn_embed)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/model/attention.py\", line 117, in forward\n",
      "    x = module(x, bias, mask_attn_embed)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/model/attention.py\", line 96, in forward\n",
      "    x = x + self.attn(self.norm1(x), bias, mask_attn = mask_attn)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/model/attention.py\", line 61, in forward\n",
      "    x, attn_weight = self.attention(q, k, v, bias=bias, mask_attn=mask_attn)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/projects/CellNavi/model/attention.py\", line 23, in forward\n",
      "    attn = self.dropout(F.softmax(attn, dim=-1))\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/modules/dropout.py\", line 58, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/nn/functional.py\", line 1266, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU 1 has a total capacty of 15.72 GiB of which 321.94 MiB is free. Process 2612071 has 12.16 GiB memory in use. Including non-PyTorch memory, this process has 3.24 GiB memory in use. Of the allocated memory 2.72 GiB is allocated by PyTorch, and 147.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "[2024-11-12 19:06:02,334] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3627547 closing signal SIGTERM\n",
      "[2024-11-12 19:06:02,335] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3627548 closing signal SIGTERM\n",
      "[2024-11-12 19:06:02,799] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 3627545) of binary: /homes/gws/tianzew/miniconda3/envs/cellnavi/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/distributed/run.py\", line 806, in main\n",
      "    run(args)\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/distributed/run.py\", line 797, in run\n",
      "    elastic_launch(\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/homes/gws/tianzew/miniconda3/envs/cellnavi/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "/homes/gws/tianzew/projects/CellNavi/tutorials/start_train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2024-11-12_19:06:02\n",
      "  host      : chelan.cs.washington.edu\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 3627546)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-11-12_19:06:02\n",
      "  host      : chelan.cs.washington.edu\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 3627545)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Here we use the toy dataset 'set3_example_train.h5ad' and 'set3_example_test.h5ad' as an example. \n",
    "## The dataset link has been given in CellNavi/README.md.\n",
    "\n",
    "import os\n",
    "\n",
    "os.system('bash launch_train.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results and evaluate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we load results on step 1000 as an example. \n",
    "## The link for 'checkpoint-step-1000.pth' has been given in README.md.\n",
    "\n",
    "import os\n",
    "\n",
    "os.system('python load_results.py -c 1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ABCB10    AKAP12      ALX4  APOBEC3C  APOBEC3D  \\\n",
      "TGCATCCTCGATCCAA-4 -7.821463 -1.156066  0.904565 -5.127326 -7.951521   \n",
      "TTGGATGGTATCCTCC-2 -7.477587 -1.947112 -1.975892 -1.696544 -7.003691   \n",
      "AACCACAGTCTCCCTA-1 -9.641579 -3.978698 -5.091012 -5.724802 -5.395859   \n",
      "TAGAGTCTCATGGATC-4 -1.639565 -2.339934  0.846601 -3.660203 -7.996193   \n",
      "TTTCAGTTCCATTCGC-2 -3.726980 -3.369183 -4.184911  0.105774 -1.985862   \n",
      "\n",
      "                       APOL2   ARHGDIB    BICDL2      CBY1       CD2  ...  \\\n",
      "TGCATCCTCGATCCAA-4 -1.957271  2.360333 -5.758391 -6.885813 -9.281010  ...   \n",
      "TTGGATGGTATCCTCC-2 -2.546962  1.258157 -2.950146 -0.769823 -4.229147  ...   \n",
      "AACCACAGTCTCCCTA-1 -5.997128 -5.460759 -0.255089 -5.033724 -3.466392  ...   \n",
      "TAGAGTCTCATGGATC-4 -2.124491  1.050665 -0.941778  1.620585 -2.813236  ...   \n",
      "TTTCAGTTCCATTCGC-2 -2.452409  2.454847 -1.646882 -0.831029 -1.429325  ...   \n",
      "\n",
      "                       TBX21  TNFRSF1A   TNFRSF1B   TNFRSF9  TNFRSF12A  \\\n",
      "TGCATCCTCGATCCAA-4 -5.753242 -6.170871 -10.717887 -5.622791  -1.512885   \n",
      "TTGGATGGTATCCTCC-2 -5.560549 -3.188946 -10.100318 -3.876570   0.070525   \n",
      "AACCACAGTCTCCCTA-1 -5.730026 -2.677795  -4.256061 -3.211844   1.078254   \n",
      "TAGAGTCTCATGGATC-4 -3.543861 -5.370579 -10.807867 -0.852403   0.740322   \n",
      "TTTCAGTTCCATTCGC-2 -5.872741 -4.059673  -7.269981 -2.935251   0.625919   \n",
      "\n",
      "                    TRAF3IP2    TRIM21      VAV1       WT1  pred_gene  \n",
      "TGCATCCTCGATCCAA-4 -8.452597 -1.819332 -5.750784 -2.827259      IL1R1  \n",
      "TTGGATGGTATCCTCC-2 -3.797031 -4.854851 -7.181687  0.396741       LAT2  \n",
      "AACCACAGTCTCCCTA-1 -3.936965 -5.897006 -8.137145 -3.409272       CD27  \n",
      "TAGAGTCTCATGGATC-4 -3.069075  0.221845 -9.051618 -1.450138       SLA2  \n",
      "TTTCAGTTCCATTCGC-2 -4.718899 -2.151842 -6.627671  0.087041       LAT2  \n",
      "\n",
      "[5 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('set3_test_example_results.csv', index_col=0)\n",
    "df['pred_gene'] = df.idxmax(axis=1)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy (for toy dataset): 0.510\n",
      "Testing F1 score (for toy dataset): 0.498\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_h5ad('../dataset_full/set3_example_test.h5ad')\n",
    "perturb_gene = adata.obs['perturbation'].values\n",
    "\n",
    "\n",
    "perturb_gene = adata.obs['perturbation'].values\n",
    "pred_gene = df['pred_gene'].values\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(perturb_gene, pred_gene)\n",
    "f1 = f1_score(perturb_gene, pred_gene, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Testing accuracy (for toy dataset): {accuracy:.3f}\")\n",
    "print(f\"Testing F1 score (for toy dataset): {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellnavi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
